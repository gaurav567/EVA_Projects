{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iteration_4_1st DNN_A4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "<h3>1.Increased No of Epochs\n",
        "  <br> 2. Inreased Batch size  and Learning rate</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-zqPk0Dhjan",
        "colab_type": "text"
      },
      "source": [
        "<h3>Import Libraries and modules</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "53ed268d-56d1-4941-db66-ca92eba6207a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add , BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "7e1e78aa-08ea-4dc1-b30b-b7814ddb92f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff762041160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "9c1029bc-2d50-44d8-84ba-ee427ec51d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "04429887-66db-488e-a757-1343d810f9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "0e2b9a0e-5c81-4322-ef36-253c9e9ce674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "\n",
        "from keras.layers import Activation\n",
        "model1 = Sequential()\n",
        "\n",
        "\n",
        "                                                                                  #input - conv - receptive feild\n",
        "                                                                                  #input_conv|Receptive Field|output  \n",
        "\n",
        "model1.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1)))      #28x28 |3x3|26x26\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Convolution2D(16, 3, 3, activation='relu'))                            #26x26 |5x5|24x24\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Convolution2D(16, 3, 3, activation='relu'))                            #24x24 |7x7|22x22\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))                                         #      |14x14|11x11    \n",
        "model1.add(Convolution2D(10, 1, 1, activation='relu'))                                #11x11 |14x14|11x11 \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Convolution2D(16,3,3, activation='relu'))                              #11x11 |16x16|9x9 \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Convolution2D(16,3,3, activation='relu'))                              #9x9   |18x18|7x7 \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "#model1.add(Convolution2D(256,3,3,activation='relu'))                             \n",
        "#model1.add(Convolution2D(512,3,3,activation='relu'))                             \n",
        "#model1.add(Convolution2D(10,3,3,activation='relu'))                             \n",
        "model1.add(Convolution2D(10, 1, activation='relu'))\n",
        "model1.add(Convolution2D(10,7))                                                   #using kernel size 7 directly.  \n",
        "\n",
        "model1.add(Flatten())\n",
        "model1.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "9897a445-57ce-4a4e-9ecc-e46ad325f046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_33 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 11, 11, 10)        170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,238\n",
            "Trainable params: 13,070\n",
            "Non-trainable params: 168\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "outputId": "9ba87d27-4ec4-4542-91c2-f049c03d1391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2091
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.004), metrics=['accuracy'])\n",
        "\n",
        "model1.fit(X_train, Y_train, batch_size=128, epochs=30, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.1975 - acc: 0.9366 - val_loss: 0.0560 - val_acc: 0.9822\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0587 - acc: 0.9823 - val_loss: 0.0368 - val_acc: 0.9883\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0453 - acc: 0.9856 - val_loss: 0.0351 - val_acc: 0.9895\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0392 - acc: 0.9870 - val_loss: 0.0282 - val_acc: 0.9909\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0336 - acc: 0.9892 - val_loss: 0.0271 - val_acc: 0.9914\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0311 - acc: 0.9897 - val_loss: 0.0224 - val_acc: 0.9929\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0266 - acc: 0.9917 - val_loss: 0.0236 - val_acc: 0.9921\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0246 - acc: 0.9923 - val_loss: 0.0251 - val_acc: 0.9915\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0257 - acc: 0.9916 - val_loss: 0.0237 - val_acc: 0.9921\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0223 - acc: 0.9928 - val_loss: 0.0219 - val_acc: 0.9928\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0226 - acc: 0.9929 - val_loss: 0.0234 - val_acc: 0.9921\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0205 - acc: 0.9931 - val_loss: 0.0231 - val_acc: 0.9923\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0192 - acc: 0.9937 - val_loss: 0.0199 - val_acc: 0.9929\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.0201 - val_acc: 0.9929\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.0187 - val_acc: 0.9936\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0175 - acc: 0.9942 - val_loss: 0.0206 - val_acc: 0.9938\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0156 - acc: 0.9951 - val_loss: 0.0201 - val_acc: 0.9933\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0164 - acc: 0.9944 - val_loss: 0.0226 - val_acc: 0.9927\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0152 - acc: 0.9950 - val_loss: 0.0204 - val_acc: 0.9928\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.0192 - val_acc: 0.9939\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0152 - acc: 0.9948 - val_loss: 0.0183 - val_acc: 0.9939\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0196 - val_acc: 0.9938\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0134 - acc: 0.9954 - val_loss: 0.0192 - val_acc: 0.9941\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0137 - acc: 0.9954 - val_loss: 0.0198 - val_acc: 0.9930\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0132 - acc: 0.9957 - val_loss: 0.0199 - val_acc: 0.9935\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0138 - acc: 0.9953 - val_loss: 0.0192 - val_acc: 0.9937\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0140 - acc: 0.9953 - val_loss: 0.0201 - val_acc: 0.9934\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0127 - acc: 0.9954 - val_loss: 0.0190 - val_acc: 0.9940\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0123 - acc: 0.9958 - val_loss: 0.0204 - val_acc: 0.9940\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0205 - val_acc: 0.9931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f64f8554710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "987x1s_Uwhy8",
        "colab_type": "text"
      },
      "source": [
        "<h3>Conclusion</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qon-A_JLqtZ-",
        "colab_type": "text"
      },
      "source": [
        "Achieved 99.41 Accuracy at 23rd epoch.\n",
        "\n",
        "Drawback-:\n",
        "Accuracy not consistent.\n",
        "\n",
        "-------------------------------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model1.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "640c41c7-e6ac-4087-c300-df196a47f562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.020518906447895644, 0.9931]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model1.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "5272984f-7afb-4d18-e980-ea61f69e3309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.01038088e-13 1.67411657e-11 3.29837890e-09 1.58732352e-08\n",
            "  2.26387546e-14 1.03558763e-12 5.95082377e-18 1.00000000e+00\n",
            "  1.89548355e-13 7.92189780e-09]\n",
            " [7.25308036e-09 9.73269607e-07 9.99998927e-01 1.04415171e-10\n",
            "  2.67111444e-10 1.77275589e-15 1.78039087e-07 5.85105011e-12\n",
            "  8.69813643e-09 5.25459971e-12]\n",
            " [1.16043786e-10 9.99994993e-01 1.84171242e-07 2.29421193e-08\n",
            "  1.88482022e-06 3.21451772e-08 2.19192682e-08 2.58668229e-06\n",
            "  2.91813933e-08 1.91871578e-07]\n",
            " [9.99907970e-01 1.09631305e-15 5.43699805e-08 7.75671020e-12\n",
            "  1.55854334e-08 1.59818159e-10 9.13815384e-05 1.21382182e-09\n",
            "  6.53961862e-09 6.07154675e-07]\n",
            " [1.42035116e-11 1.99976091e-10 4.77963447e-09 1.84337485e-12\n",
            "  9.99999523e-01 1.21737891e-16 7.13131550e-12 7.25984939e-10\n",
            "  1.02805445e-10 4.80490883e-07]\n",
            " [1.52745139e-09 9.99975443e-01 4.68032886e-06 8.42725445e-09\n",
            "  9.26446603e-07 2.23717378e-09 1.33338602e-08 1.85893587e-05\n",
            "  2.36996101e-07 1.67462503e-07]\n",
            " [9.40539980e-21 4.96122006e-08 1.58567562e-10 1.00430394e-16\n",
            "  9.99999881e-01 2.53220269e-13 1.33462870e-17 4.61719125e-08\n",
            "  7.74575515e-09 7.57964642e-08]\n",
            " [2.57551727e-12 6.81415413e-09 5.90089719e-08 8.25968183e-10\n",
            "  1.19033793e-04 4.15977164e-09 3.30710225e-14 2.69777587e-08\n",
            "  2.87598004e-06 9.99878049e-01]\n",
            " [2.18969660e-07 3.73930921e-13 3.86260979e-09 1.66257650e-11\n",
            "  5.50315544e-14 8.81570578e-01 1.18310079e-01 1.76433989e-11\n",
            "  1.18815777e-04 2.81691314e-07]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0c2b_GBq5EF",
        "colab_type": "text"
      },
      "source": [
        "Modified network - Changing a bit layers position and Kernels on the same "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8KKxAVGjtjr",
        "colab_type": "code",
        "outputId": "0dc181fb-5760-428f-a80a-5c8b2cb88019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model2 = Sequential()\n",
        "\n",
        "\n",
        "                                                                                 \n",
        "                                                                                    \n",
        "\n",
        "model2.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1)))#26    \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "model2.add(Convolution2D(16, 3, 3, activation='relu'))                       #24  \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "model2.add(Convolution2D(10, 1, 1, activation='relu'))                       #24\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))                                    #12                   \n",
        "                                                                                  \n",
        "model2.add(Convolution2D(16, 3, 3, activation='relu'))                       #10             \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "model2.add(Convolution2D(16,3,3, activation='relu'))                          #8             \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "model2.add(Convolution2D(16,3,3, activation='relu'))                          #6            \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "model2.add(Convolution2D(16,3,3, activation='relu'))                          #4            \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "#model1.add(Convolution2D(256,3,3,activation='relu'))                               \n",
        "#model1.add(Convolution2D(512,3,3,activation='relu'))                             \n",
        "#model1.add(Convolution2D(10,3,3,activation='relu'))                              \n",
        "#model1.add(Convolution2D(10, 1, activation='relu'))\n",
        "model2.add(Convolution2D(10,4,4))                                                    \n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9k3LqbRsoM_",
        "colab_type": "code",
        "outputId": "c5dbcab7-aaf6-4cdc-89e0-c51be207dbf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 10)        170       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,072\n",
            "Trainable params: 12,892\n",
            "Non-trainable params: 180\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0-YZhUIjt1d",
        "colab_type": "code",
        "outputId": "e65add7c-cd6d-470c-e419-a1b5ae54828a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2091
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X_train, Y_train, batch_size=128, epochs=30, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.2283 - acc: 0.9284 - val_loss: 0.0563 - val_acc: 0.9817\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0665 - acc: 0.9789 - val_loss: 0.0374 - val_acc: 0.9884\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0496 - acc: 0.9846 - val_loss: 0.0453 - val_acc: 0.9847\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0419 - acc: 0.9865 - val_loss: 0.0418 - val_acc: 0.9872\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0381 - acc: 0.9881 - val_loss: 0.0284 - val_acc: 0.9906\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0343 - acc: 0.9890 - val_loss: 0.0328 - val_acc: 0.9903\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0300 - acc: 0.9901 - val_loss: 0.0267 - val_acc: 0.9917\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0286 - acc: 0.9911 - val_loss: 0.0206 - val_acc: 0.9937\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0274 - acc: 0.9917 - val_loss: 0.0220 - val_acc: 0.9932\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.0194 - val_acc: 0.9940\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0246 - acc: 0.9923 - val_loss: 0.0188 - val_acc: 0.9945\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0239 - acc: 0.9922 - val_loss: 0.0216 - val_acc: 0.9929\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0213 - acc: 0.9930 - val_loss: 0.0187 - val_acc: 0.9939\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0208 - acc: 0.9932 - val_loss: 0.0178 - val_acc: 0.9946\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0192 - acc: 0.9935 - val_loss: 0.0169 - val_acc: 0.9940\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0196 - val_acc: 0.9942\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0187 - acc: 0.9939 - val_loss: 0.0198 - val_acc: 0.9940\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0186 - acc: 0.9937 - val_loss: 0.0188 - val_acc: 0.9945\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.0197 - val_acc: 0.9946\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0164 - acc: 0.9948 - val_loss: 0.0184 - val_acc: 0.9948\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0159 - acc: 0.9948 - val_loss: 0.0163 - val_acc: 0.9946\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0162 - acc: 0.9946 - val_loss: 0.0175 - val_acc: 0.9951\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0175 - val_acc: 0.9948\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0155 - acc: 0.9951 - val_loss: 0.0173 - val_acc: 0.9949\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0165 - val_acc: 0.9950\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0148 - acc: 0.9950 - val_loss: 0.0188 - val_acc: 0.9944\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0140 - acc: 0.9956 - val_loss: 0.0172 - val_acc: 0.9953\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0174 - val_acc: 0.9951\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0129 - acc: 0.9956 - val_loss: 0.0169 - val_acc: 0.9949\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.0171 - val_acc: 0.9951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7319172e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP5GsyHdjuBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model2.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHyfV7QAjuNx",
        "colab_type": "code",
        "outputId": "9c4c52d7-ff3c-4046-8b5d-83c1202d76e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01714236657834699, 0.9951]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMp0jW3hjuZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model2.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QWI8Abkjuy2",
        "colab_type": "code",
        "outputId": "4b9a04b9-dac3-445d-8f44-11016df63ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.41195244e-09 2.31384135e-07 7.33760053e-10 5.00214377e-08\n",
            "  4.35332161e-08 9.55860478e-12 3.95706835e-11 9.99999762e-01\n",
            "  2.43622900e-11 5.88021045e-08]\n",
            " [6.44231193e-08 5.49325705e-07 9.99999404e-01 1.31708155e-08\n",
            "  1.59649738e-09 5.24082991e-12 9.46693479e-09 4.68432084e-08\n",
            "  5.75559653e-08 5.66246883e-10]\n",
            " [1.54089648e-08 9.99999166e-01 9.46940659e-09 7.25996763e-11\n",
            "  1.40328382e-07 1.46130796e-09 5.63131721e-07 3.48623885e-09\n",
            "  8.75732340e-08 1.19258692e-09]\n",
            " [9.99983907e-01 1.00631377e-14 2.06431601e-08 6.28882368e-09\n",
            "  1.59238098e-07 1.65845577e-08 5.61240495e-06 2.06344222e-08\n",
            "  5.98711836e-07 9.65027812e-06]\n",
            " [8.57285000e-13 6.47022613e-09 2.07372192e-11 4.72836917e-12\n",
            "  9.99993801e-01 2.66578968e-12 3.05220405e-10 1.59419561e-11\n",
            "  4.68977968e-10 6.14779083e-06]\n",
            " [5.45042100e-09 9.99999642e-01 2.81901560e-08 7.67385884e-13\n",
            "  2.52538229e-07 6.82345239e-12 1.92854959e-08 5.12808640e-08\n",
            "  2.59830557e-09 1.20703962e-08]\n",
            " [1.72202291e-12 3.28721617e-05 1.92703804e-11 3.60917407e-11\n",
            "  9.99941945e-01 4.79664708e-09 6.51439069e-10 3.01116415e-07\n",
            "  1.43732166e-06 2.33981609e-05]\n",
            " [5.31602282e-08 7.43209216e-10 6.12584563e-06 8.17851831e-09\n",
            "  1.67746966e-05 1.87921891e-08 1.10966878e-12 1.09900880e-08\n",
            "  9.51649042e-07 9.99976039e-01]\n",
            " [3.21251806e-04 2.13525738e-07 1.09840226e-08 3.01652165e-07\n",
            "  3.72492419e-11 9.80527401e-01 1.91476755e-02 2.45398333e-08\n",
            "  2.85416218e-06 3.49573412e-07]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2udK5jS0lc3n",
        "colab_type": "text"
      },
      "source": [
        "<h3>Conclusion and observations</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11TRUtJcljHh",
        "colab_type": "text"
      },
      "source": [
        "Steps Followed -:\n",
        "\n",
        "1.Parameters achieved - 13,072.\n",
        "\n",
        "2.Accuracy need to be matched 99.4 , getting Validation acc - 99.51 at 22nd epoch and 99.4 at 10th epoch , Training acc - 99.63(need to be worked out more)\n",
        "\n",
        "\n",
        "Concluding Points (Points to be taken care to achieve a expected working model) - :\n",
        "1. Kernels and layers to be tuned properly.\n",
        "2.Batch normalization should not be added after prediction layer.\n",
        "3.Dropout value should not be very high.\n",
        "4.Accuracy should be consistent(may vary a bit not much)  throughout epochs after certain threshold.\n",
        "\n",
        "---------------------------------"
      ]
    }
  ]
}
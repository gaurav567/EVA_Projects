{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "<h3>1.Increased No of Epochs\n",
        "  <br> 2. Inreased Batch size  and Learning rate</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-zqPk0Dhjan",
        "colab_type": "text"
      },
      "source": [
        "<h3>Import Libraries and modules</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add , BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f3a76f20-451b-497e-e438-84e2856259e2"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "ea7820ab-89df-446b-8adb-99e5c8e22adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f58edac8978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "e8590347-ac29-4bac-9c1b-1e874a2a5d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "650e1e56-5c60-474e-e18b-4f2628ae2941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "0e2b9a0e-5c81-4322-ef36-253c9e9ce674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "\n",
        "from keras.layers import Activation\n",
        "model1 = Sequential()\n",
        "\n",
        "\n",
        "                                                                                  #input - conv - receptive feild\n",
        "                                                                                  #input_conv|Receptive Field|output  \n",
        "\n",
        "model1.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1)))      #28x28 |3x3|26x26\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Convolution2D(16, 3, 3, activation='relu'))                            #26x26 |5x5|24x24\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Convolution2D(16, 3, 3, activation='relu'))                            #24x24 |7x7|22x22\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))                                         #      |14x14|11x11    \n",
        "model1.add(Convolution2D(10, 1, 1, activation='relu'))                                #11x11 |14x14|11x11 \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Convolution2D(16,3,3, activation='relu'))                              #11x11 |16x16|9x9 \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Convolution2D(16,3,3, activation='relu'))                              #9x9   |18x18|7x7 \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1))\n",
        "#model1.add(Convolution2D(256,3,3,activation='relu'))                             \n",
        "#model1.add(Convolution2D(512,3,3,activation='relu'))                             \n",
        "#model1.add(Convolution2D(10,3,3,activation='relu'))                             \n",
        "model1.add(Convolution2D(10, 1, activation='relu'))\n",
        "model1.add(Convolution2D(10,7))                                                   #using kernel size 7 directly.  \n",
        "\n",
        "model1.add(Flatten())\n",
        "model1.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "9897a445-57ce-4a4e-9ecc-e46ad325f046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_33 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 11, 11, 10)        170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,238\n",
            "Trainable params: 13,070\n",
            "Non-trainable params: 168\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "outputId": "9ba87d27-4ec4-4542-91c2-f049c03d1391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2091
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.004), metrics=['accuracy'])\n",
        "\n",
        "model1.fit(X_train, Y_train, batch_size=128, epochs=30, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.1975 - acc: 0.9366 - val_loss: 0.0560 - val_acc: 0.9822\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0587 - acc: 0.9823 - val_loss: 0.0368 - val_acc: 0.9883\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0453 - acc: 0.9856 - val_loss: 0.0351 - val_acc: 0.9895\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0392 - acc: 0.9870 - val_loss: 0.0282 - val_acc: 0.9909\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0336 - acc: 0.9892 - val_loss: 0.0271 - val_acc: 0.9914\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0311 - acc: 0.9897 - val_loss: 0.0224 - val_acc: 0.9929\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0266 - acc: 0.9917 - val_loss: 0.0236 - val_acc: 0.9921\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0246 - acc: 0.9923 - val_loss: 0.0251 - val_acc: 0.9915\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0257 - acc: 0.9916 - val_loss: 0.0237 - val_acc: 0.9921\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0223 - acc: 0.9928 - val_loss: 0.0219 - val_acc: 0.9928\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0226 - acc: 0.9929 - val_loss: 0.0234 - val_acc: 0.9921\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0205 - acc: 0.9931 - val_loss: 0.0231 - val_acc: 0.9923\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0192 - acc: 0.9937 - val_loss: 0.0199 - val_acc: 0.9929\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.0201 - val_acc: 0.9929\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.0187 - val_acc: 0.9936\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0175 - acc: 0.9942 - val_loss: 0.0206 - val_acc: 0.9938\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0156 - acc: 0.9951 - val_loss: 0.0201 - val_acc: 0.9933\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0164 - acc: 0.9944 - val_loss: 0.0226 - val_acc: 0.9927\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0152 - acc: 0.9950 - val_loss: 0.0204 - val_acc: 0.9928\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.0192 - val_acc: 0.9939\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0152 - acc: 0.9948 - val_loss: 0.0183 - val_acc: 0.9939\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0196 - val_acc: 0.9938\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0134 - acc: 0.9954 - val_loss: 0.0192 - val_acc: 0.9941\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0137 - acc: 0.9954 - val_loss: 0.0198 - val_acc: 0.9930\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0132 - acc: 0.9957 - val_loss: 0.0199 - val_acc: 0.9935\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0138 - acc: 0.9953 - val_loss: 0.0192 - val_acc: 0.9937\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0140 - acc: 0.9953 - val_loss: 0.0201 - val_acc: 0.9934\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0127 - acc: 0.9954 - val_loss: 0.0190 - val_acc: 0.9940\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0123 - acc: 0.9958 - val_loss: 0.0204 - val_acc: 0.9940\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0205 - val_acc: 0.9931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f64f8554710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "987x1s_Uwhy8",
        "colab_type": "text"
      },
      "source": [
        "<h3>Conclusion</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qon-A_JLqtZ-",
        "colab_type": "text"
      },
      "source": [
        "Achieved 99.41 Accuracy at 23rd epoch.\n",
        "\n",
        "Drawback-:\n",
        "Accuracy not consistent.\n",
        "\n",
        "-------------------------------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model1.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "640c41c7-e6ac-4087-c300-df196a47f562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.020518906447895644, 0.9931]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model1.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "5272984f-7afb-4d18-e980-ea61f69e3309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.01038088e-13 1.67411657e-11 3.29837890e-09 1.58732352e-08\n",
            "  2.26387546e-14 1.03558763e-12 5.95082377e-18 1.00000000e+00\n",
            "  1.89548355e-13 7.92189780e-09]\n",
            " [7.25308036e-09 9.73269607e-07 9.99998927e-01 1.04415171e-10\n",
            "  2.67111444e-10 1.77275589e-15 1.78039087e-07 5.85105011e-12\n",
            "  8.69813643e-09 5.25459971e-12]\n",
            " [1.16043786e-10 9.99994993e-01 1.84171242e-07 2.29421193e-08\n",
            "  1.88482022e-06 3.21451772e-08 2.19192682e-08 2.58668229e-06\n",
            "  2.91813933e-08 1.91871578e-07]\n",
            " [9.99907970e-01 1.09631305e-15 5.43699805e-08 7.75671020e-12\n",
            "  1.55854334e-08 1.59818159e-10 9.13815384e-05 1.21382182e-09\n",
            "  6.53961862e-09 6.07154675e-07]\n",
            " [1.42035116e-11 1.99976091e-10 4.77963447e-09 1.84337485e-12\n",
            "  9.99999523e-01 1.21737891e-16 7.13131550e-12 7.25984939e-10\n",
            "  1.02805445e-10 4.80490883e-07]\n",
            " [1.52745139e-09 9.99975443e-01 4.68032886e-06 8.42725445e-09\n",
            "  9.26446603e-07 2.23717378e-09 1.33338602e-08 1.85893587e-05\n",
            "  2.36996101e-07 1.67462503e-07]\n",
            " [9.40539980e-21 4.96122006e-08 1.58567562e-10 1.00430394e-16\n",
            "  9.99999881e-01 2.53220269e-13 1.33462870e-17 4.61719125e-08\n",
            "  7.74575515e-09 7.57964642e-08]\n",
            " [2.57551727e-12 6.81415413e-09 5.90089719e-08 8.25968183e-10\n",
            "  1.19033793e-04 4.15977164e-09 3.30710225e-14 2.69777587e-08\n",
            "  2.87598004e-06 9.99878049e-01]\n",
            " [2.18969660e-07 3.73930921e-13 3.86260979e-09 1.66257650e-11\n",
            "  5.50315544e-14 8.81570578e-01 1.18310079e-01 1.76433989e-11\n",
            "  1.18815777e-04 2.81691314e-07]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0c2b_GBq5EF",
        "colab_type": "text"
      },
      "source": [
        "Modified network - Changing a bit layers position and Kernels on the same "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8KKxAVGjtjr",
        "colab_type": "code",
        "outputId": "0dc181fb-5760-428f-a80a-5c8b2cb88019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model2 = Sequential()\n",
        "\n",
        "\n",
        "                                                                                 \n",
        "                                                                                    \n",
        "\n",
        "model2.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1)))#26    \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "model2.add(Convolution2D(16, 3, 3, activation='relu'))                       #24  \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "model2.add(Convolution2D(10, 1, 1, activation='relu'))                       #24\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))                                    #12                   \n",
        "                                                                                  \n",
        "model2.add(Convolution2D(16, 3, 3, activation='relu'))                       #10             \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "model2.add(Convolution2D(16,3,3, activation='relu'))                          #8             \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "model2.add(Convolution2D(16,3,3, activation='relu'))                          #6            \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "model2.add(Convolution2D(16,3,3, activation='relu'))                          #4            \n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "#model1.add(Convolution2D(256,3,3,activation='relu'))                               \n",
        "#model1.add(Convolution2D(512,3,3,activation='relu'))                             \n",
        "#model1.add(Convolution2D(10,3,3,activation='relu'))                              \n",
        "#model1.add(Convolution2D(10, 1, activation='relu'))\n",
        "model2.add(Convolution2D(10,4,4))                                                    \n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9k3LqbRsoM_",
        "colab_type": "code",
        "outputId": "c5dbcab7-aaf6-4cdc-89e0-c51be207dbf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 10)        170       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,072\n",
            "Trainable params: 12,892\n",
            "Non-trainable params: 180\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0-YZhUIjt1d",
        "colab_type": "code",
        "outputId": "e65add7c-cd6d-470c-e419-a1b5ae54828a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2091
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X_train, Y_train, batch_size=128, epochs=30, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.2283 - acc: 0.9284 - val_loss: 0.0563 - val_acc: 0.9817\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0665 - acc: 0.9789 - val_loss: 0.0374 - val_acc: 0.9884\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0496 - acc: 0.9846 - val_loss: 0.0453 - val_acc: 0.9847\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0419 - acc: 0.9865 - val_loss: 0.0418 - val_acc: 0.9872\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0381 - acc: 0.9881 - val_loss: 0.0284 - val_acc: 0.9906\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0343 - acc: 0.9890 - val_loss: 0.0328 - val_acc: 0.9903\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0300 - acc: 0.9901 - val_loss: 0.0267 - val_acc: 0.9917\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0286 - acc: 0.9911 - val_loss: 0.0206 - val_acc: 0.9937\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0274 - acc: 0.9917 - val_loss: 0.0220 - val_acc: 0.9932\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.0194 - val_acc: 0.9940\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0246 - acc: 0.9923 - val_loss: 0.0188 - val_acc: 0.9945\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0239 - acc: 0.9922 - val_loss: 0.0216 - val_acc: 0.9929\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0213 - acc: 0.9930 - val_loss: 0.0187 - val_acc: 0.9939\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0208 - acc: 0.9932 - val_loss: 0.0178 - val_acc: 0.9946\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0192 - acc: 0.9935 - val_loss: 0.0169 - val_acc: 0.9940\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0196 - val_acc: 0.9942\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0187 - acc: 0.9939 - val_loss: 0.0198 - val_acc: 0.9940\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0186 - acc: 0.9937 - val_loss: 0.0188 - val_acc: 0.9945\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.0197 - val_acc: 0.9946\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0164 - acc: 0.9948 - val_loss: 0.0184 - val_acc: 0.9948\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0159 - acc: 0.9948 - val_loss: 0.0163 - val_acc: 0.9946\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0162 - acc: 0.9946 - val_loss: 0.0175 - val_acc: 0.9951\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0175 - val_acc: 0.9948\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0155 - acc: 0.9951 - val_loss: 0.0173 - val_acc: 0.9949\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0165 - val_acc: 0.9950\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0148 - acc: 0.9950 - val_loss: 0.0188 - val_acc: 0.9944\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0140 - acc: 0.9956 - val_loss: 0.0172 - val_acc: 0.9953\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0174 - val_acc: 0.9951\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0129 - acc: 0.9956 - val_loss: 0.0169 - val_acc: 0.9949\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.0171 - val_acc: 0.9951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7319172e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP5GsyHdjuBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model2.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHyfV7QAjuNx",
        "colab_type": "code",
        "outputId": "9c4c52d7-ff3c-4046-8b5d-83c1202d76e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01714236657834699, 0.9951]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMp0jW3hjuZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model2.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QWI8Abkjuy2",
        "colab_type": "code",
        "outputId": "4b9a04b9-dac3-445d-8f44-11016df63ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.41195244e-09 2.31384135e-07 7.33760053e-10 5.00214377e-08\n",
            "  4.35332161e-08 9.55860478e-12 3.95706835e-11 9.99999762e-01\n",
            "  2.43622900e-11 5.88021045e-08]\n",
            " [6.44231193e-08 5.49325705e-07 9.99999404e-01 1.31708155e-08\n",
            "  1.59649738e-09 5.24082991e-12 9.46693479e-09 4.68432084e-08\n",
            "  5.75559653e-08 5.66246883e-10]\n",
            " [1.54089648e-08 9.99999166e-01 9.46940659e-09 7.25996763e-11\n",
            "  1.40328382e-07 1.46130796e-09 5.63131721e-07 3.48623885e-09\n",
            "  8.75732340e-08 1.19258692e-09]\n",
            " [9.99983907e-01 1.00631377e-14 2.06431601e-08 6.28882368e-09\n",
            "  1.59238098e-07 1.65845577e-08 5.61240495e-06 2.06344222e-08\n",
            "  5.98711836e-07 9.65027812e-06]\n",
            " [8.57285000e-13 6.47022613e-09 2.07372192e-11 4.72836917e-12\n",
            "  9.99993801e-01 2.66578968e-12 3.05220405e-10 1.59419561e-11\n",
            "  4.68977968e-10 6.14779083e-06]\n",
            " [5.45042100e-09 9.99999642e-01 2.81901560e-08 7.67385884e-13\n",
            "  2.52538229e-07 6.82345239e-12 1.92854959e-08 5.12808640e-08\n",
            "  2.59830557e-09 1.20703962e-08]\n",
            " [1.72202291e-12 3.28721617e-05 1.92703804e-11 3.60917407e-11\n",
            "  9.99941945e-01 4.79664708e-09 6.51439069e-10 3.01116415e-07\n",
            "  1.43732166e-06 2.33981609e-05]\n",
            " [5.31602282e-08 7.43209216e-10 6.12584563e-06 8.17851831e-09\n",
            "  1.67746966e-05 1.87921891e-08 1.10966878e-12 1.09900880e-08\n",
            "  9.51649042e-07 9.99976039e-01]\n",
            " [3.21251806e-04 2.13525738e-07 1.09840226e-08 3.01652165e-07\n",
            "  3.72492419e-11 9.80527401e-01 1.91476755e-02 2.45398333e-08\n",
            "  2.85416218e-06 3.49573412e-07]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXtlYSSQ-Vqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2udK5jS0lc3n",
        "colab_type": "text"
      },
      "source": [
        "<h3>Conclusion and observations</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11TRUtJcljHh",
        "colab_type": "text"
      },
      "source": [
        "Steps Followed -:\n",
        "\n",
        "1.Parameters achieved - 13,072.\n",
        "\n",
        "2.Accuracy need to be matched 99.4 , getting Validation acc - 99.51 at 22nd epoch and 99.4 at 10th epoch , Training acc - 99.63(need to be worked out more)\n",
        "\n",
        "\n",
        "Concluding Points (Points to be taken care to achieve a expected working model) - :\n",
        "1. Kernels and layers to be tuned properly.\n",
        "2.Batch normalization should not be added after prediction layer.\n",
        "3.Dropout value should not be very high.\n",
        "4.Accuracy should be consistent(may vary a bit not much)  throughout epochs after certain threshold.\n",
        "\n",
        "---------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HguVEWzf-hlU",
        "colab_type": "text"
      },
      "source": [
        "<h3>Image Normalization.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MmZWlTRokBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a2050da3-1920-49c2-c39a-f3452008ff32"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "width, height, channels = X_train.shape[1], X_train.shape[2], 1\n",
        "X_train = X_train.reshape((X_train.shape[0], width, height, channels))\n",
        "X_test = X_test.reshape((X_test.shape[0], width, height, channels))\n",
        "# report pixel means and standard deviations\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), X_test.std()))\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(X_train)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(X_train, Y_train, batch_size=64)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(X_train, Y_train, batch_size=len(X_train), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=0.131 (0.308), test=0.133 (0.310)\n",
            "Data Generator mean=0.131, std=0.308\n",
            "(64, 28, 28, 1) 0.01073329 1.0083636\n",
            "(60000, 28, 28, 1) -4.9324944e-07 0.9999959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOWLET6JqDoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "2d2f0c3a-195a-4b3b-80ca-df6de858e9fc"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model3 = Sequential()\n",
        "\n",
        "\n",
        "                                                                                 \n",
        "                                                                                    \n",
        "\n",
        "model3.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1)))#26    \n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "model3.add(Convolution2D(16, 3, 3, activation='relu'))                       #24  \n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "model3.add(Convolution2D(10, 1, 1, activation='relu'))                       #24\n",
        "model3.add(MaxPooling2D(pool_size=(2,2)))                                    #12                   \n",
        "                                                                                  \n",
        "model3.add(Convolution2D(16, 3, 3, activation='relu'))                       #10             \n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "model3.add(Convolution2D(16,3,3, activation='relu'))                          #8             \n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "model3.add(Convolution2D(16,3,3, activation='relu'))                          #6            \n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "model3.add(Convolution2D(16,3,3, activation='relu'))                          #4            \n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "#model1.add(Convolution2D(256,3,3,activation='relu'))                               \n",
        "#model1.add(Convolution2D(512,3,3,activation='relu'))                             \n",
        "#model1.add(Convolution2D(10,3,3,activation='relu'))                              \n",
        "#model1.add(Convolution2D(10, 1, activation='relu'))\n",
        "model3.add(Convolution2D(10,4,4))                                                    \n",
        "\n",
        "model3.add(Flatten())\n",
        "model3.add(Activation('softmax'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXnytybmqDja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "d18822f0-995c-4962-b3e8-aed8597b9555"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 10)        170       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,072\n",
            "Trainable params: 12,892\n",
            "Non-trainable params: 180\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmipMC4yqDcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2091
        },
        "outputId": "aa29ceea-66ea-41b4-e4b9-169bfe4176bd"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model3.fit(X_train, Y_train, batch_size=128, epochs=30, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.2270 - acc: 0.9281 - val_loss: 0.0862 - val_acc: 0.9724\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0679 - acc: 0.9790 - val_loss: 0.0548 - val_acc: 0.9826\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0541 - acc: 0.9827 - val_loss: 0.0567 - val_acc: 0.9829\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0429 - acc: 0.9859 - val_loss: 0.0383 - val_acc: 0.9884\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0380 - acc: 0.9879 - val_loss: 0.0369 - val_acc: 0.9885\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0340 - acc: 0.9890 - val_loss: 0.0363 - val_acc: 0.9882\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0315 - acc: 0.9898 - val_loss: 0.0302 - val_acc: 0.9905\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0290 - acc: 0.9908 - val_loss: 0.0269 - val_acc: 0.9920\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0278 - acc: 0.9909 - val_loss: 0.0279 - val_acc: 0.9918\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0263 - acc: 0.9915 - val_loss: 0.0264 - val_acc: 0.9933\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0259 - acc: 0.9917 - val_loss: 0.0302 - val_acc: 0.9916\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0223 - acc: 0.9927 - val_loss: 0.0249 - val_acc: 0.9931\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0224 - acc: 0.9927 - val_loss: 0.0258 - val_acc: 0.9930\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0220 - acc: 0.9933 - val_loss: 0.0295 - val_acc: 0.9921\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0205 - acc: 0.9932 - val_loss: 0.0252 - val_acc: 0.9928\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0195 - acc: 0.9934 - val_loss: 0.0288 - val_acc: 0.9924\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0201 - acc: 0.9932 - val_loss: 0.0313 - val_acc: 0.9914\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0268 - val_acc: 0.9931\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.0283 - val_acc: 0.9926\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0273 - val_acc: 0.9924\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0169 - acc: 0.9942 - val_loss: 0.0232 - val_acc: 0.9940\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0235 - val_acc: 0.9939\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0161 - acc: 0.9944 - val_loss: 0.0248 - val_acc: 0.9928\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0169 - acc: 0.9944 - val_loss: 0.0233 - val_acc: 0.9935\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0160 - acc: 0.9947 - val_loss: 0.0238 - val_acc: 0.9937\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0145 - acc: 0.9954 - val_loss: 0.0245 - val_acc: 0.9939\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0163 - acc: 0.9947 - val_loss: 0.0214 - val_acc: 0.9943\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0134 - acc: 0.9955 - val_loss: 0.0253 - val_acc: 0.9935\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0140 - acc: 0.9953 - val_loss: 0.0236 - val_acc: 0.9933\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0154 - acc: 0.9949 - val_loss: 0.0244 - val_acc: 0.9935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58bc419d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzlYoEzzqDRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model3.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWq8CzW9qC8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgP1gniLtZCq",
        "colab_type": "text"
      },
      "source": [
        "<h3>Regularization - Corrected in model 6</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWlZK4E3uv0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import regularizer\n",
        "from keras.regularizers import l2\n",
        "# instantiate regularizer\n",
        "reg = l2(0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8UtqefCtW2t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "2e1c9720-76ef-43f4-9ae9-5afad20299c7"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model4 = Sequential()\n",
        "\n",
        "\n",
        "                                                                                 \n",
        "                                                                                    \n",
        "\n",
        "model4.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1)))#26    \n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.1))\n",
        "model4.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "\n",
        "model4.add(Convolution2D(16, 3, 3, activation='relu'))                       #24  \n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.1))\n",
        "model4.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "\n",
        "model4.add(Convolution2D(10, 1, 1, activation='relu'))                       #24\n",
        "model4.add(MaxPooling2D(pool_size=(2,2)))                                    #12                   \n",
        "                                                                                  \n",
        "model4.add(Convolution2D(16, 3, 3, activation='relu'))                       #10             \n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.1))\n",
        "model4.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "model4.add(Convolution2D(16,3,3, activation='relu'))                          #8             \n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.1))\n",
        "model4.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "model4.add(Convolution2D(16,3,3, activation='relu'))                          #6            \n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.1))\n",
        "model4.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "model4.add(Convolution2D(16,3,3, activation='relu'))                          #4            \n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.1))\n",
        "model4.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "#model1.add(Convolution2D(256,3,3,activation='relu'))                               \n",
        "#model1.add(Convolution2D(512,3,3,activation='relu'))                             \n",
        "#model1.add(Convolution2D(10,3,3,activation='relu'))                              \n",
        "#model1.add(Convolution2D(10, 1, activation='relu'))\n",
        "model4.add(Convolution2D(10,4,4))                                                    \n",
        "\n",
        "model4.add(Flatten())\n",
        "model4.add(Activation('softmax'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ituP4ZEptXUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        },
        "outputId": "b26dc9f0-ac1f-4429-b57b-cb2fe38c88b9"
      },
      "source": [
        "model4.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_26 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 26, 26, 32)        352       \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 24, 24, 16)        4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 24, 24, 32)        544       \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10, 10, 32)        544       \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 8, 8, 16)          4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8, 8, 32)          544       \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 6, 6, 16)          4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 6, 6, 32)          544       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 4, 4, 16)          4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 4, 4, 32)          544       \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 1, 1, 10)          5130      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 28,944\n",
            "Trainable params: 28,764\n",
            "Non-trainable params: 180\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_EwmQk3tXdc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "efeb6bc4-7729-444b-d30f-56f2b7623747"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model4.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model4.fit(X_train, Y_train, batch_size=128, epochs=10, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 13s 218us/step - loss: 114.7464 - acc: 0.1355 - val_loss: 4.6313 - val_acc: 0.0958\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 2.3099 - acc: 0.1119 - val_loss: 4.1501 - val_acc: 0.1135\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 2.3060 - acc: 0.1124 - val_loss: 2.3411 - val_acc: 0.1135\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 2.3053 - acc: 0.1123 - val_loss: 2.3311 - val_acc: 0.1135\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 2.3026 - acc: 0.1124 - val_loss: 2.3102 - val_acc: 0.1135\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 2.3027 - acc: 0.1124 - val_loss: 2.3130 - val_acc: 0.1028\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 2.3022 - acc: 0.1124 - val_loss: 2.3150 - val_acc: 0.1135\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 2.3020 - acc: 0.1124 - val_loss: 2.3128 - val_acc: 0.1135\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 2.3019 - acc: 0.1124 - val_loss: 2.3082 - val_acc: 0.1135\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 2.3019 - acc: 0.1124 - val_loss: 2.3050 - val_acc: 0.1135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58bc456a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjFdFm2UtXlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model4.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBhN6HJpuaMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d384024-bde2-47c5-88a3-eff64190f5b9"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3020065952301025, 0.1135]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFNg5u6jywjp",
        "colab_type": "text"
      },
      "source": [
        "<h3>Relu After Batch Normalization</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5D8s79ryuEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "5c8e053d-2cdc-4705-d939-dc8dd46ee5ef"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model5 = Sequential()\n",
        "\n",
        "\n",
        "                                                                                 \n",
        "                                                                                    \n",
        "\n",
        "model5.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1)))#26    \n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "#model5.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "\n",
        "model5.add(Convolution2D(16, 3, 3, activation='relu'))                       #24  \n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "#model5.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "\n",
        "model5.add(Convolution2D(10, 1, 1, activation='relu'))                       #24\n",
        "model5.add(MaxPooling2D(pool_size=(2,2)))                                    #12                   \n",
        "                                                                                  \n",
        "model5.add(Convolution2D(16, 3, 3, activation='relu'))                       #10             \n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "#model5.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "model5.add(Convolution2D(16,3,3, activation='relu'))                          #8             \n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "#model5.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "model5.add(Convolution2D(16,3,3, activation='relu'))                          #6            \n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "#model5.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "model5.add(Convolution2D(16,3,3, activation='relu'))                          #4            \n",
        "model5.add(BatchNormalization())\n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "#model5.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "\n",
        "\n",
        "#model1.add(Convolution2D(256,3,3,activation='relu'))                               \n",
        "#model1.add(Convolution2D(512,3,3,activation='relu'))                             \n",
        "#model1.add(Convolution2D(10,3,3,activation='relu'))                              \n",
        "#model1.add(Convolution2D(10, 1, activation='relu'))\n",
        "model5.add(Convolution2D(10,4,4))                                                    \n",
        "\n",
        "model5.add(Flatten())\n",
        "model5.add(Activation('softmax'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSoubUNnyuUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        },
        "outputId": "0a615b21-165d-488e-915e-387cbd1ce224"
      },
      "source": [
        "model5.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_34 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 24, 24, 10)        170       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,072\n",
            "Trainable params: 12,892\n",
            "Non-trainable params: 180\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWN9EcD6yud6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2091
        },
        "outputId": "823f2554-56ca-413f-d7f2-b0a655b12e5f"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model5.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model5.fit(X_train, Y_train, batch_size=128, epochs=30, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.3334 - acc: 0.9028 - val_loss: 0.0826 - val_acc: 0.9738\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0787 - acc: 0.9751 - val_loss: 0.0515 - val_acc: 0.9834\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0592 - acc: 0.9817 - val_loss: 0.0467 - val_acc: 0.9851\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0495 - acc: 0.9849 - val_loss: 0.0464 - val_acc: 0.9870\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0447 - acc: 0.9856 - val_loss: 0.0428 - val_acc: 0.9866\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0413 - acc: 0.9867 - val_loss: 0.0352 - val_acc: 0.9901\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0365 - acc: 0.9882 - val_loss: 0.0326 - val_acc: 0.9902\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0345 - acc: 0.9890 - val_loss: 0.0359 - val_acc: 0.9894\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0327 - acc: 0.9896 - val_loss: 0.0309 - val_acc: 0.9903\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0307 - acc: 0.9902 - val_loss: 0.0243 - val_acc: 0.9929\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0293 - acc: 0.9905 - val_loss: 0.0247 - val_acc: 0.9925\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0280 - acc: 0.9910 - val_loss: 0.0263 - val_acc: 0.9922\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0265 - acc: 0.9915 - val_loss: 0.0230 - val_acc: 0.9931\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0269 - acc: 0.9911 - val_loss: 0.0259 - val_acc: 0.9922\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0246 - acc: 0.9917 - val_loss: 0.0233 - val_acc: 0.9925\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0242 - acc: 0.9924 - val_loss: 0.0236 - val_acc: 0.9930\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0216 - acc: 0.9931 - val_loss: 0.0241 - val_acc: 0.9926\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0232 - acc: 0.9924 - val_loss: 0.0226 - val_acc: 0.9933\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0218 - val_acc: 0.9931\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0223 - val_acc: 0.9934\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0210 - acc: 0.9935 - val_loss: 0.0210 - val_acc: 0.9936\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0207 - acc: 0.9935 - val_loss: 0.0220 - val_acc: 0.9937\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0190 - acc: 0.9937 - val_loss: 0.0222 - val_acc: 0.9929\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0195 - acc: 0.9933 - val_loss: 0.0228 - val_acc: 0.9931\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0197 - val_acc: 0.9939\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0191 - acc: 0.9936 - val_loss: 0.0219 - val_acc: 0.9928\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0173 - acc: 0.9940 - val_loss: 0.0215 - val_acc: 0.9930\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.0207 - val_acc: 0.9932\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0177 - acc: 0.9941 - val_loss: 0.0201 - val_acc: 0.9937\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0245 - val_acc: 0.9928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f589340dcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76V1NO4_yuoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model5.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZXiMXPLz9S8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5uvTXL43JkZ",
        "colab_type": "text"
      },
      "source": [
        "<h3>Including All conditions in One Model\n",
        "<br>1.image normalization\n",
        "<br>2.L2 regularization\n",
        "<br>3.ReLU after BN\n",
        "<br>4.Run your new code for 40 epochs and save the model with highest validation accuracy\n",
        "<br>5.Find out 25 misclassified images from the validation dataset and create an image gallery</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5xPPsWm4Maw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "f69e1f25-dc87-471e-980e-8f166d9e72bc"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model6 = Sequential()\n",
        "\n",
        "\n",
        "                                                                                 \n",
        "                                                                                    \n",
        "\n",
        "model6.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1)))#26    \n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(Convolution2D(10,1,1,activity_regularizer=l2(0.001)))\n",
        "model6.add(Dropout(0.1))\n",
        "#model6.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "#model6.add(Convolution2D(10, (3,3), activity_regularizer=l1(0.001)))\n",
        "\n",
        "model6.add(Convolution2D(16, 3, 3, activation='relu'))                       #24  \n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(Convolution2D(10,1,1, activity_regularizer=l2(0.001)))\n",
        "model6.add(Dropout(0.1))\n",
        "#model6.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "\n",
        "\n",
        "model6.add(Convolution2D(10, 1, 1, activation='relu'))                       #24\n",
        "model6.add(MaxPooling2D(pool_size=(2,2)))                                    #12                   \n",
        "                                                                                  \n",
        "model6.add(Convolution2D(16, 3, 3, activation='relu'))                       #10             \n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(Convolution2D(10,1,1, activity_regularizer=l2(0.001)))\n",
        "model6.add(Dropout(0.1))\n",
        "#model6.add(Convolution2D(16, (3,3), activity_regularizer=l1(0.001)))\n",
        "#model6.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "#model6.add(Convolution2D(10,1,1, activity_regularizer=l2(0.001)))\n",
        "\n",
        "\n",
        "model6.add(Convolution2D(16,3,3, activation='relu'))                          #8             \n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(Convolution2D(10,1,1, activity_regularizer=l2(0.001)))\n",
        "model6.add(Dropout(0.1))\n",
        "#model6.add(Convolution2D(16, (3,3), activity_regularizer=l1(0.001)))\n",
        "#model6.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "#model6.add(Convolution2D(10,1,1, activity_regularizer=l2(0.001)))\n",
        "\n",
        "model6.add(Convolution2D(16,3,3, activation='relu'))                          #6            \n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(Convolution2D(10,1,1, activity_regularizer=l2(0.001)))\n",
        "model6.add(Dropout(0.1))\n",
        "#model6.add(Convolution2D(16, (3,3), activity_regularizer=l1(0.001)))\n",
        "#model6.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "#model6.add(Convolution2D(10,1,1, activity_regularizer=l2(0.001)))\n",
        "\n",
        "model6.add(Convolution2D(16,3,3, activation='relu'))                          #4            \n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(Convolution2D(10,1,1, activity_regularizer=l2(0.001)))\n",
        "model6.add(Dropout(0.1))\n",
        "#model6.add(Convolution2D(16, (3,3), activity_regularizer=l1(0.001)))\n",
        "#model6.add(Dense(32, activation='linear', activity_regularizer=l2(0.001)))\n",
        "#model6.add(Convolution2D(10,1,1, activity_regularizer=l2(0.001)))\n",
        "\n",
        "#model1.add(Convolution2D(256,3,3,activation='relu'))                               \n",
        "#model1.add(Convolution2D(512,3,3,activation='relu'))                             \n",
        "#model1.add(Convolution2D(10,3,3,activation='relu'))                              \n",
        "#model1.add(Convolution2D(10, 1, activation='relu'))\n",
        "model6.add(Convolution2D(10,4,4))                                                    \n",
        "\n",
        "model6.add(Flatten())\n",
        "model6.add(Activation('softmax'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activity_regularizer=<keras.reg...)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activity_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activity_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activity_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activity_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activity_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgvyy7k84Mqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1326
        },
        "outputId": "aa0aeba2-ef68-4ab8-b641-16c04a6d942a"
      },
      "source": [
        "model6.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_190 (Conv2D)          (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_115 (Bat (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_100 (Activation)  (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_191 (Conv2D)          (None, 26, 26, 10)        110       \n",
            "_________________________________________________________________\n",
            "dropout_114 (Dropout)        (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_192 (Conv2D)          (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_116 (Bat (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_101 (Activation)  (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_193 (Conv2D)          (None, 24, 24, 10)        170       \n",
            "_________________________________________________________________\n",
            "dropout_115 (Dropout)        (None, 24, 24, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_194 (Conv2D)          (None, 24, 24, 10)        110       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_195 (Conv2D)          (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_117 (Bat (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_102 (Activation)  (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_196 (Conv2D)          (None, 10, 10, 10)        170       \n",
            "_________________________________________________________________\n",
            "dropout_116 (Dropout)        (None, 10, 10, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_197 (Conv2D)          (None, 8, 8, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_118 (Bat (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_103 (Activation)  (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_198 (Conv2D)          (None, 8, 8, 10)          170       \n",
            "_________________________________________________________________\n",
            "dropout_117 (Dropout)        (None, 8, 8, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_199 (Conv2D)          (None, 6, 6, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_119 (Bat (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_104 (Activation)  (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_200 (Conv2D)          (None, 6, 6, 10)          170       \n",
            "_________________________________________________________________\n",
            "dropout_118 (Dropout)        (None, 6, 6, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_201 (Conv2D)          (None, 4, 4, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_120 (Bat (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_105 (Activation)  (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_202 (Conv2D)          (None, 4, 4, 10)          170       \n",
            "_________________________________________________________________\n",
            "dropout_119 (Dropout)        (None, 4, 4, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_203 (Conv2D)          (None, 1, 1, 10)          1610      \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_106 (Activation)  (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 10,420\n",
            "Trainable params: 10,240\n",
            "Non-trainable params: 180\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5piqXvB4M1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2771
        },
        "outputId": "88df79f5-2bcd-41a6-bf47-c34ee43a3335"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model6.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model6.fit(X_train, Y_train, batch_size=128, epochs=40, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 20s 340us/step - loss: 42.9139 - acc: 0.3544 - val_loss: 5.1043 - val_acc: 0.1170\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 1.8490 - acc: 0.7515 - val_loss: 2.3858 - val_acc: 0.6026\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 1.2731 - acc: 0.8346 - val_loss: 3.8293 - val_acc: 0.2568\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 1.0647 - acc: 0.8632 - val_loss: 4.9882 - val_acc: 0.1239\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.9447 - acc: 0.8776 - val_loss: 1.2936 - val_acc: 0.7017\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.9443 - acc: 0.8823 - val_loss: 2.4251 - val_acc: 0.7852\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.8874 - acc: 0.8953 - val_loss: 0.6648 - val_acc: 0.8946\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.7265 - acc: 0.9018 - val_loss: 5.8394 - val_acc: 0.1148\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.7012 - acc: 0.9068 - val_loss: 0.9271 - val_acc: 0.8616\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.6469 - acc: 0.9159 - val_loss: 1.8576 - val_acc: 0.6052\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.7119 - acc: 0.9011 - val_loss: 4.9941 - val_acc: 0.1135\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.5681 - acc: 0.9211 - val_loss: 3.0884 - val_acc: 0.6722\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.5320 - acc: 0.9264 - val_loss: 5.7015 - val_acc: 0.1144\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.5444 - acc: 0.9267 - val_loss: 0.9053 - val_acc: 0.7889\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.4647 - acc: 0.9325 - val_loss: 4.6470 - val_acc: 0.1135\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.6785 - acc: 0.9226 - val_loss: 2.1731 - val_acc: 0.5339\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.4979 - acc: 0.9307 - val_loss: 0.7727 - val_acc: 0.9268\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.4662 - acc: 0.9330 - val_loss: 1.5989 - val_acc: 0.6906\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.5150 - acc: 0.9283 - val_loss: 3.5176 - val_acc: 0.5682\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.4276 - acc: 0.9407 - val_loss: 3.2142 - val_acc: 0.1711\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.4355 - acc: 0.9395 - val_loss: 6.4184 - val_acc: 0.1135\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.4166 - acc: 0.9408 - val_loss: 2.9296 - val_acc: 0.3236\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.3970 - acc: 0.9453 - val_loss: 0.6505 - val_acc: 0.8919\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.3741 - acc: 0.9455 - val_loss: 2.0385 - val_acc: 0.4419\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.3469 - acc: 0.9474 - val_loss: 1.2263 - val_acc: 0.6895\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.4492 - acc: 0.9386 - val_loss: 1.4853 - val_acc: 0.5846\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.4319 - acc: 0.9404 - val_loss: 1.5266 - val_acc: 0.7126\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.3462 - acc: 0.9493 - val_loss: 3.9423 - val_acc: 0.1872\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.3193 - acc: 0.9517 - val_loss: 0.7625 - val_acc: 0.7848\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.3587 - acc: 0.9454 - val_loss: 1.1891 - val_acc: 0.6554\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.3055 - acc: 0.9534 - val_loss: 0.9014 - val_acc: 0.7549\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.3093 - acc: 0.9542 - val_loss: 2.2628 - val_acc: 0.4616\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.3709 - acc: 0.9454 - val_loss: 5.8334 - val_acc: 0.1135\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 0.3233 - acc: 0.9510 - val_loss: 1.5181 - val_acc: 0.7579\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.2898 - acc: 0.9560 - val_loss: 1.5271 - val_acc: 0.5800\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.3355 - acc: 0.9516 - val_loss: 6.0953 - val_acc: 0.1135\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.3133 - acc: 0.9518 - val_loss: 3.9706 - val_acc: 0.2128\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.3786 - acc: 0.9452 - val_loss: 12.1971 - val_acc: 0.1358\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.2860 - acc: 0.9574 - val_loss: 2.7945 - val_acc: 0.3830\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.2901 - acc: 0.9542 - val_loss: 2.6921 - val_acc: 0.3464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58875e37f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3IRAPbN4NAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model6.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBILxNe44NEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "593eeda5-23ab-4c23-9b2b-7452353e4327"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.5328401466369628, 0.3464]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvviAfQQcutR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model6.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Y1glwY4NNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "22415700-2de9-4931-f205-ecf1eff654d6"
      },
      "source": [
        "print(y_pred[:9])\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.89623463e-03 2.17291806e-03 1.93129946e-03 4.51987656e-03\n",
            "  2.85272923e-04 3.68012377e-04 4.25157987e-06 9.79429603e-01\n",
            "  7.41473224e-04 7.65111111e-03]\n",
            " [1.42435925e-02 9.16528642e-01 5.39250970e-02 5.69544034e-03\n",
            "  3.40319006e-03 2.02549435e-03 1.31421816e-03 1.29898079e-03\n",
            "  5.52296638e-04 1.01306161e-03]\n",
            " [5.30133257e-04 9.88159001e-01 1.24193961e-03 1.59623707e-03\n",
            "  2.41398183e-03 5.61951834e-04 1.28066546e-04 4.43630386e-03\n",
            "  1.78753180e-04 7.53560395e-04]\n",
            " [5.45816235e-02 5.18968642e-01 4.04330827e-02 2.23641172e-01\n",
            "  2.17576381e-02 1.55062834e-02 1.06962654e-03 7.64204338e-02\n",
            "  5.38451644e-03 4.22369987e-02]\n",
            " [2.39053788e-03 3.49935025e-01 1.67315960e-01 3.37475017e-02\n",
            "  3.63892317e-01 3.19938138e-02 8.47801473e-03 1.01547968e-03\n",
            "  4.32824483e-03 3.69031578e-02]\n",
            " [5.30133257e-04 9.88159001e-01 1.24193961e-03 1.59623707e-03\n",
            "  2.41398183e-03 5.61951834e-04 1.28066546e-04 4.43630386e-03\n",
            "  1.78753180e-04 7.53560395e-04]\n",
            " [2.06714869e-03 9.09383036e-03 1.38048651e-02 5.85092232e-02\n",
            "  2.79226959e-01 4.88173589e-02 4.24151134e-04 4.50940073e-01\n",
            "  2.74133193e-03 1.34375125e-01]\n",
            " [8.50031245e-03 4.63258140e-02 1.18209971e-02 9.32856742e-03\n",
            "  4.48952429e-03 9.37539502e-04 7.08291118e-05 9.02750552e-01\n",
            "  2.46599643e-03 1.33099016e-02]\n",
            " [7.92215858e-03 9.40166600e-03 8.57700482e-02 2.52336413e-01\n",
            "  2.22901851e-02 5.53417265e-01 4.83502354e-03 2.49047461e-03\n",
            "  3.14099491e-02 3.01267821e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMb0MXUB4NaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bd1e1dd-1dbf-47e2-d2dd-cd8d248eed53"
      },
      "source": [
        "print(y_test[:9])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Ak5MJ44NX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1292
        },
        "outputId": "37d0a5bd-5569-4e0e-be3b-5c477ec12d6c"
      },
      "source": [
        "print(y_pred[:25])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.89623463e-03 2.17291806e-03 1.93129946e-03 4.51987656e-03\n",
            "  2.85272923e-04 3.68012377e-04 4.25157987e-06 9.79429603e-01\n",
            "  7.41473224e-04 7.65111111e-03]\n",
            " [1.42435925e-02 9.16528642e-01 5.39250970e-02 5.69544034e-03\n",
            "  3.40319006e-03 2.02549435e-03 1.31421816e-03 1.29898079e-03\n",
            "  5.52296638e-04 1.01306161e-03]\n",
            " [5.30133257e-04 9.88159001e-01 1.24193961e-03 1.59623707e-03\n",
            "  2.41398183e-03 5.61951834e-04 1.28066546e-04 4.43630386e-03\n",
            "  1.78753180e-04 7.53560395e-04]\n",
            " [5.45816235e-02 5.18968642e-01 4.04330827e-02 2.23641172e-01\n",
            "  2.17576381e-02 1.55062834e-02 1.06962654e-03 7.64204338e-02\n",
            "  5.38451644e-03 4.22369987e-02]\n",
            " [2.39053788e-03 3.49935025e-01 1.67315960e-01 3.37475017e-02\n",
            "  3.63892317e-01 3.19938138e-02 8.47801473e-03 1.01547968e-03\n",
            "  4.32824483e-03 3.69031578e-02]\n",
            " [5.30133257e-04 9.88159001e-01 1.24193961e-03 1.59623707e-03\n",
            "  2.41398183e-03 5.61951834e-04 1.28066546e-04 4.43630386e-03\n",
            "  1.78753180e-04 7.53560395e-04]\n",
            " [2.06714869e-03 9.09383036e-03 1.38048651e-02 5.85092232e-02\n",
            "  2.79226959e-01 4.88173589e-02 4.24151134e-04 4.50940073e-01\n",
            "  2.74133193e-03 1.34375125e-01]\n",
            " [8.50031245e-03 4.63258140e-02 1.18209971e-02 9.32856742e-03\n",
            "  4.48952429e-03 9.37539502e-04 7.08291118e-05 9.02750552e-01\n",
            "  2.46599643e-03 1.33099016e-02]\n",
            " [7.92215858e-03 9.40166600e-03 8.57700482e-02 2.52336413e-01\n",
            "  2.22901851e-02 5.53417265e-01 4.83502354e-03 2.49047461e-03\n",
            "  3.14099491e-02 3.01267821e-02]\n",
            " [1.77408755e-02 2.21821759e-03 5.00606047e-03 1.40139023e-02\n",
            "  1.17561370e-02 7.28776678e-03 4.30527834e-05 5.67804992e-01\n",
            "  5.10767195e-03 3.69021326e-01]\n",
            " [1.18878800e-02 9.61321890e-01 3.72750801e-03 2.44851178e-03\n",
            "  5.02433395e-03 4.94550960e-03 9.52654285e-04 4.22387244e-03\n",
            "  1.60393212e-03 3.86393350e-03]\n",
            " [1.94893610e-02 1.19195841e-02 2.17286665e-02 7.52093375e-01\n",
            "  1.49750886e-02 1.19249701e-01 2.80683301e-03 1.06293028e-02\n",
            "  7.59542407e-03 3.95125784e-02]\n",
            " [2.27974262e-02 1.44614549e-02 2.12050229e-02 2.00535059e-01\n",
            "  8.81894864e-03 2.76087523e-02 1.83055192e-04 4.92463768e-01\n",
            "  1.32446848e-02 1.98681861e-01]\n",
            " [5.25989868e-02 4.21392053e-01 5.11841588e-02 6.07833266e-02\n",
            "  8.63239449e-03 5.97777590e-03 3.59702070e-04 3.60239238e-01\n",
            "  6.37366390e-03 3.24586928e-02]\n",
            " [5.30133257e-04 9.88159001e-01 1.24193961e-03 1.59623707e-03\n",
            "  2.41398183e-03 5.61951834e-04 1.28066546e-04 4.43630386e-03\n",
            "  1.78753180e-04 7.53560395e-04]\n",
            " [2.12592958e-03 5.82711864e-03 1.65176820e-02 6.56530082e-01\n",
            "  1.13226427e-03 1.88126385e-01 4.77877475e-04 1.20294452e-01\n",
            "  4.52722842e-03 4.44088969e-03]\n",
            " [1.35468811e-01 1.24642551e-02 1.35244966e-01 1.73369069e-02\n",
            "  4.84371092e-03 7.54545704e-02 8.70935386e-04 3.93853992e-01\n",
            "  1.79184023e-02 2.06543446e-01]\n",
            " [4.60325880e-03 2.05488852e-03 2.17364496e-03 6.03214139e-03\n",
            "  2.29119614e-04 5.15382213e-04 5.18380921e-06 9.74630773e-01\n",
            "  7.17704475e-04 9.03792027e-03]\n",
            " [3.52522568e-03 5.63787937e-01 4.20721844e-02 3.14201593e-01\n",
            "  1.62743125e-02 8.91193375e-03 1.37173815e-03 3.57640646e-02\n",
            "  7.89844990e-03 6.19256869e-03]\n",
            " [1.27388886e-03 5.66943049e-01 5.03153950e-02 8.50204900e-02\n",
            "  2.01323196e-01 2.88784038e-02 3.72630637e-03 2.12246366e-02\n",
            "  2.15021521e-03 3.91444415e-02]\n",
            " [9.65241157e-03 7.11683463e-03 9.04527027e-03 2.27799080e-02\n",
            "  7.70578161e-03 4.04103473e-03 2.95105274e-05 8.09478581e-01\n",
            "  4.86933021e-03 1.25281319e-01]\n",
            " [1.29231205e-03 1.72602683e-02 6.55554328e-03 6.59079552e-01\n",
            "  2.01001558e-02 2.57157326e-01 6.35798415e-03 9.08372365e-03\n",
            "  2.08878936e-03 2.10243613e-02]\n",
            " [3.30897987e-01 7.52353966e-02 5.69155924e-02 2.71820217e-01\n",
            "  2.66302712e-02 1.33636475e-01 3.22753489e-02 1.01423925e-02\n",
            "  8.45572073e-03 5.39905466e-02]\n",
            " [2.98822648e-04 6.84699102e-04 1.23102698e-04 1.90273337e-02\n",
            "  8.60360597e-05 9.76291478e-01 5.18231827e-04 3.68846115e-04\n",
            "  3.15070152e-04 2.28642928e-03]\n",
            " [1.85543147e-03 6.05946481e-01 7.18705282e-02 2.41967943e-03\n",
            "  2.50432462e-01 1.74270514e-02 1.10512441e-02 1.75849348e-02\n",
            "  1.43349427e-03 1.99786928e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fULmWNht4NVy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87fd3a98-6a42-40c1-c782-95e9d675f800"
      },
      "source": [
        "print(y_test[:25])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BobZYzFl4NTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuW4vtm_4NRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjcJOECX4NJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqt0J5FD4M-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}